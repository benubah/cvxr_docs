---
title: Near Isotonic and Near Convex Regression
author: Anqi Fu and Balasubramanian Narasimhan
date: '2017-11-02'
slug: cvxr_near-isotonic-and-near-convex-regression
bibliography: ../bibtex/cvxr_refs.bib
link-citations: true
categories: []
tags: []
---



<p>Given a set of data points <span class="math inline">\(y \in {\mathbf R}^m\)</span>, <span class="citation">R. J. Tibshirani, Hoefling, and Tibshirani (<a href="#ref-TibshiraniHoefling:2011">2011</a>)</span> fit a nearly-isotonic approximation <span class="math inline">\(\beta \in {\mathbf R}^m\)</span> by solving</p>
$$
<span class="math display">\[\begin{array}{ll}

\underset{\beta}{\mbox{minimize}} &amp; \frac{1}{2}\sum_{i=1}^m (y_i -
\beta_i)^2 + \lambda \sum_{i=1}^{m-1}(\beta_i - \beta_{i+1})_+,

\end{array}\]</span>
<p>$$</p>
<p>where <span class="math inline">\(\lambda \geq 0\)</span> is a penalty parameter and <span class="math inline">\(x_+ =\max(x,0)\)</span>. This can be directly formulated in <code>cvxr</code>. As an example, we use global warming data from the <a href="http://cdiac.ess-dive.lbl.gov/ftp/trends/temp/jonescru/">Carbon Dioxide Information Analysis Center (CDIAC)</a>. The data points are the annual temperature anomalies relative to the 1961–1990 mean.</p>
<pre class="r"><code>suppressMessages(suppressWarnings(library(cvxr)))
data(cdiac)
str(cdiac)</code></pre>
<pre><code>## &#39;data.frame&#39;:    166 obs. of  14 variables:
##  $ year  : int  1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 ...
##  $ jan   : num  -0.702 -0.303 -0.308 -0.177 -0.36 -0.176 -0.119 -0.512 -0.532 -0.307 ...
##  $ feb   : num  -0.284 -0.362 -0.477 -0.33 -0.28 -0.4 -0.373 -0.344 -0.707 -0.192 ...
##  $ mar   : num  -0.732 -0.485 -0.505 -0.318 -0.284 -0.303 -0.513 -0.434 -0.55 -0.334 ...
##  $ apr   : num  -0.57 -0.445 -0.559 -0.352 -0.349 -0.217 -0.371 -0.646 -0.517 -0.203 ...
##  $ may   : num  -0.325 -0.302 -0.209 -0.268 -0.23 -0.336 -0.119 -0.567 -0.651 -0.31 ...
##  $ jun   : num  -0.213 -0.189 -0.038 -0.179 -0.215 -0.16 -0.288 -0.31 -0.58 -0.25 ...
##  $ jul   : num  -0.128 -0.215 -0.016 -0.059 -0.228 -0.268 -0.297 -0.544 -0.324 -0.285 ...
##  $ aug   : num  -0.233 -0.153 -0.195 -0.148 -0.163 -0.159 -0.305 -0.327 -0.28 -0.104 ...
##  $ sep   : num  -0.444 -0.108 -0.125 -0.409 -0.115 -0.339 -0.459 -0.393 -0.339 -0.575 ...
##  $ oct   : num  -0.452 -0.063 -0.216 -0.359 -0.188 -0.211 -0.384 -0.467 -0.2 -0.255 ...
##  $ nov   : num  -0.19 -0.03 -0.187 -0.256 -0.369 -0.212 -0.608 -0.665 -0.644 -0.316 ...
##  $ dec   : num  -0.268 -0.067 0.083 -0.444 -0.232 -0.51 -0.44 -0.356 -0.3 -0.363 ...
##  $ annual: num  -0.375 -0.223 -0.224 -0.271 -0.246 -0.271 -0.352 -0.46 -0.466 -0.286 ...</code></pre>
<p>Since we plan to fit the regression and also get some idea of the standard errors, we write a function that computes the fit for use in bootstrapping. In what follows, we use a very small number of bootstrap samples as the fits are time consuming.</p>
<pre class="r"><code>neariso_fit &lt;- function(y, lambda) {
    m &lt;- length(y)
    beta &lt;- Variable(m)
    obj &lt;- 0.5 * sum((y - beta)^2) + lambda * sum(pos(diff(beta)))
    prob &lt;- Problem(Minimize(obj))
    solve(prob)$getValue(beta)
}</code></pre>
<p>The <code>pos</code> atom evaluates <span class="math inline">\(x_+\)</span> elementwise on the input expression.</p>
<p>The <code>boot</code> library provides all the tools for bootstrapping but requires a statistic function that takes particular arguments: a data frame, followed by the bootstrap indices and any other arguments (<span class="math inline">\(\lambda\)</span> for instance). This is shown below.</p>
<pre class="r"><code>neariso_fit_stat &lt;- function(data, index, lambda) {
    sample &lt;- data[index,]                  # Bootstrap sample of rows
    sample &lt;- sample[order(sample$year),]   # Order ascending by year
    neariso_fit(sample$annual, lambda)
}</code></pre>
<pre class="r"><code>library(boot)

boot.neariso &lt;- boot(data = cdiac, statistic = neariso_fit_stat, R = 10, lambda = 0.44)

ci.neariso &lt;- t(sapply(seq_len(nrow(cdiac)),
                            function(i) boot.ci(boot.out = boot.neariso, conf = 0.95,
                                                type = &quot;norm&quot;, index = i)$normal[-1]))
data.neariso &lt;- data.frame(year = cdiac$year, annual = cdiac$annual, est = boot.neariso$t0,
                              lower = ci.neariso[, 1], upper = ci.neariso[, 2])</code></pre>
<p>We can now plot the fit and confidence bands for the near isotonic fit.</p>
<pre class="r"><code>library(ggplot2)
(plot.neariso &lt;- ggplot(data = data.neariso) +
     geom_point(mapping = aes(year, annual), color = &quot;red&quot;) +
     geom_line(mapping = aes(year, est), color = &quot;blue&quot;) +
     geom_ribbon(mapping = aes(x = year, ymin = lower,ymax = upper),alpha=0.3) +
     labs(x = &quot;Year&quot;, y = &quot;Temperature Anomalies&quot;)
)</code></pre>
<p><img src="/post/examples/cvxr_near-isotonic-and-near-convex-regression_files/figure-html/unnamed-chunk-5-1.png" width="672" /> The curve follows the data well, but exhibits some choppiness in regions with a steep trend.</p>
<p>For a smoother curve, we can solve for the nearly-convex fit described in the same paper:</p>
<p><span class="math display">\[
\begin{array}{ll}
\underset{\beta}{\mbox{minimize}} &amp; \frac{1}{2}\sum_{i=1}^m (y_i -
\beta_i)^2 + \lambda \sum_{i=1}^{m-2}(\beta_i - 2\beta_{i+1} +
\beta_{i+2})_+ \end{array} 
\]</span></p>
<p>This replaces the first difference term with an approximation to the second derivative at <span class="math inline">\(\beta_{i+1}\)</span>. In <code>cvxr</code>, the only change necessary is the penalty line: replacing <code>diff(x)</code> by <code>diff(diff(x))</code>.</p>
<pre class="r"><code>nearconvex_fit &lt;- function(y, lambda) {
    m &lt;- length(y)
    beta &lt;- Variable(m)
    penalty &lt;- sum(pos(diff(beta)))
    obj &lt;- 0.5 * sum((y - beta)^2) + lambda * sum(pos(diff(diff(beta))))
    prob &lt;- Problem(Minimize(obj))
    solve(prob)$getValue(beta)
}

nearconvex_fit_stat &lt;- function(data, index, lambda) {
    sample &lt;- data[index,]                  # Bootstrap sample of rows
    sample &lt;- sample[order(sample$year),]   # Order ascending by year
    nearconvex_fit(sample$annual, lambda)
}

boot.nearconvex &lt;- boot(data = cdiac, statistic = nearconvex_fit_stat, R = 5, lambda = 0.44)

ci.nearconvex &lt;- t(sapply(seq_len(nrow(cdiac)),
                          function(i) boot.ci(boot.out = boot.nearconvex, conf = 0.95,
                                              type = &quot;norm&quot;, index = i)$normal[-1]))
data.nearconvex &lt;- data.frame(year = cdiac$year, annual = cdiac$annual, est = boot.nearconvex$t0,
                              lower = ci.nearconvex[, 1], upper = ci.nearconvex[, 2])</code></pre>
<p>The resulting curve for the near convex fit is depicted below with 95% confidence bands generated from <span class="math inline">\(R = 5\)</span> samples. Note the jagged staircase pattern has been smoothed out.</p>
<pre class="r"><code>(plot.nearconvex &lt;- ggplot(data = data.nearconvex) +
     geom_point(mapping = aes(year, annual), color = &quot;red&quot;) +
     geom_line(mapping = aes(year, est), color = &quot;blue&quot;) +
     geom_ribbon(mapping = aes(x = year, ymin = lower,ymax = upper),alpha=0.3) +
     labs(x = &quot;Year&quot;, y = &quot;Temperature Anomalies&quot;)
)</code></pre>
<p><img src="/post/examples/cvxr_near-isotonic-and-near-convex-regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div id="notes" class="section level2">
<h2>Notes</h2>
<p>We can easily extend this example to higher-order differences or lags. To make this easy, the function <code>diff</code> takes an argument <code>differences</code> is by default 1; a third-order difference is specified as <code>diff(x, differences = 3)</code>.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-TibshiraniHoefling:2011">
<p>Tibshirani, R. J., H. Hoefling, and R. Tibshirani. 2011. “Nearly-Isotonic Regression.” <em>Technometrics</em> 53 (1): 54–61.</p>
</div>
</div>
</div>
